{\rtf1\ansi\ansicpg1252\cocoartf2865
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 from pyspark.sql import SparkSession\
from pyspark.sql.functions import col\
\
spark = SparkSession.builder.getOrCreate()\
\
print("=== DELTA CONFIG PROOF ===")\
print("spark.sql.extensions =", spark.conf.get("spark.sql.extensions"))\
print("spark.sql.catalog.spark_catalog =", spark.conf.get("spark.sql.catalog.spark_catalog"))\
print("==========================")\
\
BUCKET = "nyc-taxi-datalake-lahari"\
\
RAW_PATH = f"s3://\{BUCKET\}/raw/nyc_taxi/yellow/ingestion_date=2026-01-04/yellow_tripdata_2025-08.parquet"\
DELTA_PATH = f"s3://\{BUCKET\}/curated/nyc_taxi/yellow_delta/"\
\
# Read raw parquet\
df_raw = spark.read.parquet(RAW_PATH)\
\
# Basic validation\
df_validated = (\
    df_raw\
    .filter(col("trip_distance").isNotNull())\
    .filter(col("fare_amount").isNotNull())\
)\
\
# Write Delta version 0\
df_validated.write.format("delta").mode("overwrite").save(DELTA_PATH)\
\
# Create another Delta version (append)\
df_validated.limit(100).write.format("delta").mode("append").save(DELTA_PATH)\
\
# Time travel proof\
v0 = spark.read.format("delta").option("versionAsOf", 0).load(DELTA_PATH).count()\
v1 = spark.read.format("delta").option("versionAsOf", 1).load(DELTA_PATH).count()\
\
print("VERSION_0_COUNT =", v0)\
print("VERSION_1_COUNT =", v1)\
\
spark.stop()\
}